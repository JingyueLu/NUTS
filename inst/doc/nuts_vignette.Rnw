\documentclass{article}

\usepackage{amsmath, amsthm, amssymb}
\usepackage[round]{natbib}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{algorithm}
\usepackage{algorithmic}

% The line below tells R to use knitr on this.
%\VignetteEngine{knitr::knitr}

\title{The Hamiltonian Monte Carlo and the No-U-Turn Sampler}
\author{Jingyue Lu \and Marco Palma}

\begin{document}
%\SweaveOpts{concordance=TRUE}

\maketitle

\begin{abstract}
We present the R package `NUTS', which contains functions for Hamiltonian Monte Carlo and one of its extensions called No-U-Turn Sampler with Dual Averaging.
\end{abstract}

\section{Introduction}

This project investigates the No-U-Turn Sampler (NUTS). M.D. Hoffman and A. Gelman introduced NUTS in 2011 to address the tuning issues involved in Hamiltonian Monte Carlo (HMC) algorithm.
%Using Hamiltonian Dynamics, HMC avoids simple random work behaviour by proposing distant proposals for Metropolis algorithm, thereby converging to high-dimensional target distributions at a much faster speed than other general methods.
%The performance of HMC depends heavily on two tuning parameters
%: the trajectory length and the stepsize.
%and a poor choice of these two parameters will lead to drastic decrease of the performance of HMC. NUTS is designed to specifically address the problem of tuning the trajectory length.
To be more specific, we start by introducing the theoretical ideas behind HMC and NUTS. Then we %A short theoretical foundation for both algorithms is also included. Both HMC and NUTS are
implement both methods in R to compare their performances. Especially, we are interested in how effective NUTS is as an extension of HMC.

\section{Hamiltonian Monte Carlo}

The Hamiltonian Monte Carlo (also known as hybrid Monte Carlo, introduced by \citealp{duane1987hybrid}) is a Markov chain Monte Carlo method that avoids simple random work behaviour by proposing remote states for Metropolis algorithm, thereby achieving rapid convergence to a target distribution.
%converging to high-dimensional target distributions at a much faster speed than other general methods.%that overcomes the random walk behaviour typical of this class of algorithms in order to achieve faster convergence to a target distribution.
% This is obtained by introducing for each model variable $\theta_d$ an auxiliary variable $r_d$ called momentum, whose distribution is easy to sample from (usually a standard normal distribution).
The idea of HMC is to introduce a $d$-dimensional vector $r$ called momentum (where $d$ is the dimension of the parameter vector $\theta$), independently drawn from a distribution we can easily sample from (usually a standard multivariate normal). The unnormalized joint density can be written as
$$ p(\theta,r) \propto \exp\left\{\mathcal{L}(\theta)-\frac{1}{2} r \cdot r\right\} $$
where $\mathcal{L}$ is the unnormalized logarithm of the joint posterior density of $\theta$ and $\cdot$ is an inner product.

\par Samples of $(\theta,r)$ are obtained by using the St{\"o}rmer-Verlet \textit{leapfrog integrator}. Given the gradient $\nabla_{\theta}\mathcal{L}$ and the step size $\epsilon$, the updates proceed as follows:
\begin{equation*}
r^{t+\epsilon/2}=r^t+\epsilon/2 \nabla_{\theta}\mathcal{L}(\theta^t)
\quad \theta^{t+\epsilon} = \theta^t+\epsilon r^{t+\epsilon/2} \quad
r^{t+\epsilon}=r^{t+\epsilon/2}+(\epsilon/2)\nabla_{\theta}\mathcal{L}(\theta^{t+\epsilon}).
\end{equation*}

\par The leapfrog procedure is applied $L$ times in order to generate a pair $(\tilde{\theta},\tilde{r})$. Then the proposal for the $m$-th iteration of the Markov chain is $(\tilde{\theta},-\tilde{r})$ (where the minus sign for $r$ is only used to guarantee time reversibility). According to Metropolis ratio, the proposal is accepted %using a standard Metropolis accept-reject procedure
with a probability

\begin{equation*}
\alpha=\min\left\{1,\frac{p(\tilde{\theta},\tilde{r})}{p(\theta^{m-1},r_0)}\right\}
\end{equation*}
\noindent where $r_0$ is the resampled momentum at the $m$-th iteration.

Despite the increase in efficiency, the usability and the performances of HMC are affected not only by the computation of $\nabla_{\theta}\mathcal{L}$ (that can be addressed via numerical procedures) but also by the step size $\epsilon$ and number of steps $L$ chosen within the leapfrog. Indeed, when $\epsilon$ is too large the acceptance rates will be low, whereas for small values of $\epsilon$ there will be a waste of computation because of the tiny steps. In terms of $L$, if it is too small the samples will be close to each other, but if it is too large the trajectory in the parameters space will loop back to the previous steps.

\section{No-U-Turn Sampler}

%In this section, we introduce NUTS to address the problem of tuning the trajectory length $L$. NUTS is a method that builds upon HMC. Unlike HMC, which sets a fixed trajectory length $L$ for all proposals, NUTS dynamically chooses $L$ for each proposal using the idea of No-U-Turn.

NUTS addresses the problem of tuning the number of steps $L$. In short, NUTS repeatedly doubles the length of the current trajectory until increasing $L$ no longer leads to an increased distance between the initial $\theta$ and a newly proposed $\tilde{\theta}$. That is, the $\tilde{\theta}$ makes a "U-turn".

\subsection{Derivation of simplified NUTS algorithm}
The derivation of NUTS algorithm can be divided into two parts: the conditions this algorithm has to satisfy in order to be theoretically sound and the criteria NUTS uses to stop the doubling procedure.

To simplify the derivation of NUTS, Hoffman and Gelman introduced a slice variable $u$. Simplified NUTS considers the augmented model

$$p(\theta,r,u)\propto\mathbb{I}\left[u\in\left[0,\exp\left\{\mathcal{L}(\theta)-\frac{1}{2}r\cdot r\right\}\right]\right],$$

where $\mathbb{I}[\cdot]$ is 1 if $u\in \left[0,\exp\{\mathcal{L}(\theta)-\frac{1}{2}r\cdot r\}\right]$ is true and 0 otherwise.
%The useful results of introducing a slice variable $u$ are that the conditional probabilities $p(u|\theta,r) \sim \text{Unif}(u;[0, \exp\{\mathcal{L}(\theta)-\frac{1}{2}r\cdot r\}])$ and $p(\theta,r|u) \sim \text{Unif}(\theta', r' | \exp\{\mathcal{L}(\theta)-\frac{1}{2}r\cdot r\}\geq u)$ are both uniform and hence can be easily simulated
Introducing $u$ renders the conditional probabilities $p(u|\theta,r) \sim \text{Unif}(u;[0, \exp\{\mathcal{L}(\theta)-\frac{1}{2}r\cdot r\}])$ and $p(\theta,r|u) \sim \text{Unif}(\theta', r' | \exp\{\mathcal{L}(\theta)-\frac{1}{2}r\cdot r\}\geq u)$ and hence simplifies the simulation.

\par In terms of theoretical requirements, the simplified NUTS algorithm must not only leave the target distribution invariant but also guarantee the time reversibility. Under several mild conditions, NUTS uses the following procedure to sample $\theta^{t+1}$ from $\theta^{t}$ to achieve invariant target distribution:
\begin{enumerate}
\item sample $r\sim\mathcal{N}(0,I)$,
\item sample $u\sim\text{Unif}\left(\left[0,\exp\left\{\mathcal{L}(\theta^t)-\frac{1}{2}r\cdot{r}\right\}\right]\right)$,
\item sample $\mathcal{B}$, $\mathcal{C}$ from their conditional distribution $p(\mathcal{B},\mathcal{C}|\theta^t,r,u,\epsilon)$,
\item sample $\left(\theta^{t+1},r \right)$ uniformly from the set $\mathcal{C}$.
\end{enumerate}
\noindent Here, $\mathcal{C}$ is a set of candidate position-momentum states while $\mathcal{B}$ is the set of all position-momentum states computed by leapfrog integrator during each NUTS iteration. Clearly, $\mathcal{C}\subseteq\mathcal{B}$. For the purpose of this project, we omit the proof of the validity of the procedure but only state the key observations and results. We first point out that steps 1, 2, 3 constitute a valid Gibbs sampling update for $r$, $u$, $\mathcal{B}$, $\mathcal{C}$. Secondly,
%the construction of the distribution $p(\mathcal{B},\mathcal{C}|\theta^t,r,u,\epsilon)$ relies on the strategy employed by NUTS to achieve time reversibility and will be introduced later. Thirdly and lastly,
as a result of the prequiresites of the above procedure, we use the following condition to determine whether a state in $\mathcal{B}$ is also in $\mathcal{C}$:

\begin{equation}
(\theta',r')\in\mathcal{C},\qquad \text{if}\quad u\leq \exp\left\{\mathcal{L}(\theta')-\frac{1}{2}r'\cdot r'\right\}
\label{cond1} \tag{C.1}
\end{equation}

%We now consider the time reversibility requirement. Time reversibility is important as it ensures the algorithm converge to the correct distribution. NUTS uses a recursive algorithm to preserve time reversibility.

\par For what concerns time reversibility, it is important as it ensures the algorithm converge to the target distribution. NUTS uses a recursive algorithm to preserve it. Recall that, to find a trajectory length for each NUTS interation, NUTS doubles the current trajectory repeatedly until an u-turn is encountered. To simulate forward and backward movement in time, during each doubling, NUTS allows the new subtrajectory to start from either the leftmost or rightmost point of the old trajectory and use leapfrog to trace a path either running backwards or forwards respectively. The proccess continues until stopping criteria are met. To illustrate, we assume the starting point is $(\theta_0^1,r)$, where the subscript is the number of step and the superscript is the index of the point in that step. Also, let $v\in\{1,-1\}$. $v$ is randomly choosen in each step to present the direction of movement. We are only interested in the path for $\theta$.

To simulate forward and backward movement in time, during each doubling, a new subtrajectory is traced by leapfrog either forward from the rightmost state or backward from the leftmost state until the stopping criteria are met. To illustrate, we assume the starting point is $(\theta_0^1,r)$, where the subscript is the number of doubling steps and the superscript is the index of the state in that doubling step. Also, let $v\in\{1,-1\}$ be randomly chosen in each doubling step to determine the direction of movement. We are interested in the path for $\theta$:\\
\textbf{Step j=1:}   (v= 1)  $ \Rightarrow \theta_0^1 \rightarrow \theta_1^1.$ \\
\textbf{Step j=2:}   (v= 1)  $ \Rightarrow \theta_0^1 \rightarrow \theta_1^1 \rightarrow \theta_2^1 \rightarrow \theta_2^2.$ \\
\textbf{Step j=3:}   (v=-1)  $ \Rightarrow \theta_3^4\leftarrow\theta_3^3\leftarrow\theta_3^2\leftarrow \theta_3^1\leftarrow\theta_0^1 \rightarrow \theta_1^1 \rightarrow \theta_2^1 \rightarrow \theta_2^2.$ \\
\noindent In the example above, we build a three-step path. We can also think the path after each step $j$ as a binary tree of height $j$, so final path is a binary tree of height 3
$$\underbrace{\underbrace{\underbrace{\theta_3^4\leftarrow\theta_3^3}_{\text{level }1}\leftarrow\underbrace{\theta_3^2\leftarrow \theta_3^1}_{\text{level }1}}_{\text{level }2}\leftarrow\underbrace{\underbrace{\theta_0^1 \rightarrow \theta_1^1}_{\text{level }1} \rightarrow \underbrace{\theta_2^1 \rightarrow \theta_2^2}_{\text{level }1}}_{\text{level }2}}_{\text{level }3}.$$

\par Finally, we discuss the stopping criteria used in NUTS. A straightforward and essential stopping condition for NUTS implements the idea of no-U-turn. We observe that when $\tilde{\theta}$ makes a U-turn, the following derivative
%, with respect to time, of half the squared distance (half is chosen to simplify calculations) between $\theta$ and $\tilde{\theta}$
should be less than 0:
%. Mathematically, we have
\begin{equation}
\frac{d}{dt}\frac{(\tilde{\theta}-\theta)\cdot (\tilde{\theta}-\theta)}{2} = (\tilde{\theta}-\theta)\cdot\frac{d}{dt}(\tilde{\theta}-\theta)= (\tilde{\theta}-\theta)\cdot r < 0.
\label{cond2} \tag{C.2}
\end{equation}
% Thus, the NUTS algorithm stops when:
%
% \textbf{\eqref{cond2}:}
% $$(\theta_{end}-\theta_{start})\cdot r < 0.$$
This condition is checked for each subtree and also for the whole tree. %Other than the stopping condition for U-turn, NUTS also stops expanding $\mathcal{B}$ when any newly discovered states in the continuing process are likely to have near 0 probability to be in $\mathcal{C}$ . To formulate, NUTS develops the following condition based on \eqref{cond1}:
In addition, NUTS also stops expanding $\mathcal{B}$ when any newly discovered states in the continuing process has extremely low probability to be in $\mathcal{C}$. To formulate, NUTS develops the following condition based on \eqref{cond1}:
% \textbf{\eqref{cond3}:}
% The algorithm stops when
\begin{equation}
\mathcal{L}(\theta) -\frac{1}{2}r\cdot r -\log u > -\Delta_{max}.
\label{cond3} \tag{C.3}
\end{equation}
\noindent In NUTS, $\Delta_{max}$ is set to 1000, so the algorithm continues as long as the simulation is moderately accurate.

\par So far, we have addressed all aspects needed for deriving the simplified NUTS algorithm. We summarise the simplified NUTS algorithm below.
\begin{algorithm}
\caption{Sample for a point $\tilde{\theta}$ using a NUTS iteration}
\begin{algorithmic}
\REQUIRE {The initial position $\theta_0^1$.}
\STATE {Resample $r\sim\mathcal{N}(0,I)$.}
\STATE {Resample $u\sim\text{Unif}([0,\exp\{\mathcal{L}(\theta^t)-\frac{1}{2}r\cdot r\}])$.}
\STATE\COMMENT {$j$ is the number of doubling steps we take to build a trajectory path.}
\STATE\COMMENT {$s$ is an indicator variable. It becomes 0 when a stopping criterion is met.}
\STATE {Initialise $j=0$, $s=1$, $\mathcal{C}=\{(\theta_0^1,r)\}$}
\STATE\COMMENT {Set the rightmost (+) and leftmost (-) points of the trajectory path.}
\STATE {Initialise $\theta^{+} =\theta_0^1$, $\theta^{-} =\theta_0^1$.}
\WHILE {s=1}
  \STATE{Build a binary tree of height $j$}
  \WHILE{Build a binary tree of height $j$}
    \STATE{ For each new node: check C.1 to determine whether or not to add the new node into $\mathcal{C}$.}
    \STATE{For each new node: check C.3. If Condition Three is met, set $s=0$.}
    \STATE{For each subtree: check C.2. If Condition Two is met, set $s=0$.}
  \ENDWHILE
  \STATE{Update $\theta^{+}$ and $\theta^{-}$ to be the rightmost and leftmost point of the whole path.}
  \STATE{Check C.2 for the whole path.If it is met, set $s=0$. }
  \STATE{j= j+1.}
\ENDWHILE
\STATE{Sample $\tilde{\theta}$ uniformly from $\mathcal{C}$.}
\end{algorithmic}
\end{algorithm}

% 1. Resample $r\sim\mathcal{N}(0,I)$.
% 2. Resample $u\sim\text{Unif}([0,\exp\{\mathcal{L}(\theta^t)-\frac{1}{2}r\cdot r\}])$.
% %j is the number of doubling steps we take to build a trajectory path.
% %s is an indicator variable. It becomes 0 when a stopping criterion is met.
% 3. Initialise $j=0$, $s=1$, $\mathcal{C}=\{(\theta_0^1,r)\}$.
% %Set the rightmost (+) and leftmost (-) points of the trajectory path.
% 4. Initialise $\theta^{+}=\theta_0^0$,$\theta^{-}=\theta_0^0$.
% 5. **while** s=1 do
%     1. Build a binary tree of height j
%         1. For each new node: check \eqref{cond1} to determine whether or not to add the new node into $\mathcal{C}$.
%         2. For each new node: check \eqref{cond3}. If \eqref{cond3} is met, set $s=0$.
%         3. For each subtree: check \eqref{cond2}. If \eqref{cond2} is met, set $s=0$.
%     2. For the newly generated whole path:
%         1. Update $\theta^{+}$ and $\theta^{-}$ to be the rightmost and leftmost point of the whole path.
%         2. Check \eqref{cond2}. If it is met, set $s=0$.
%         \# Update variables for while loop
%     3. j= j+1
% 6. Sample $\tilde{\theta}$ uniformly from $\mathcal{C}$.

\subsection{Efficient NUTS}
\par \citet{hoffman2014nuts} proposed an efficient version of the NUTS algorithm. Firstly, the execution is halted exactly once a stopping criterion is met instead of at the end of the corresponding doubling step. Secondly, simplified NUTS requires to store $2^j$ states to perform uniform sampling at the end. A solution for reducing this memory requirement from $O(2^j)$ to $O(j)$ is to use a more sophisticated transition kernel and to exploit the binary tree structure of the trajectory path. We refer interested reader to \citet{hoffman2014nuts} for details. The NUTS function included in the package is an efficient algorithm with these improvements implemented.

% Simplified NUTS algorithm need to evaluate log posterior probability and its gradient at $2^j-1$ points apart from $O(2^j)$ operations to check the stopping criteria \citep{hoffman2014nuts}. Furthermore, the final doubling iteration continues even when a stopping criterion is met in the middle of the process. In terms of memory, simplifed NUTS requires to store $2^j$ states to perform uniform sampling at the end. These facts seriously deterioate the efficiency of NUTS. The second issue can be easily solved by terminating the excucation of the recrusion once $s$ becomes $0$. \citet{hoffman2014nuts} prosposed a solution for reducing the meomery requirment from $O(2^j)$ to $O(j)$. The key idea of this memory reduction is to use a more sophisticated transition kernal and to exploit the binary tree structure of the trajectory path. We refer interested reader to \citet{hoffman2014nuts} for details. The NUTS function included in the package is an efficient algorithm with these improvements implemented.

\section{Dual averaging}

In \citet{hoffman2014nuts} a method based on the primal-dual algorithm by \citet{nesterov2009dual} is also provided for setting the step size $\epsilon$ for both HMC and NUTS.
%, primarily intended for stochastic convex optimization.
In the context of MCMC, considered the statistic $H_t=\delta-\alpha_t$ where $\delta$ is a specified average acceptance probability and $\alpha_t$ is the observed Metropolis one at time $t$. %Suppose that there is a tunable parameter $x \in \mathbb{R}$ for which the nonincreasing function
The key idea of the dual averaging algorithm is that, under some specific conditions, $H_t=0$ can be approached (that is, to approximate the desired average acceptance probability) by tuning $\log(\epsilon)$ using an iterative procedure. In the implementation, $\epsilon$ is tuned during the warmup phase (the user needs to specify the number of iterations of the warmup phase) and kept constant for the subsequent iterations. The user needs to specify the target mean acceptance rate $\delta$ and the number of iterations of the warmup phase.

\vspace{0.5in}

% so that $h(\log(\epsilon))\equiv \mathbb{E}_t[\alpha_t|\log(\epsilon)]=\delta$.
%
%
%
% \begin{equation*}
% h(x)=\mathbb{E}_t[H_t|x]=\lim_{T \rightarrow \infty}\frac{1}{T}\sum_{t=1}^{T}\mathbb{E}_t[H_t|x] = 0;
% \end{equation*}
% under some specific conditions $x$ can be tuned during the warmup phase to solve this limit and set it constant for the subsequent iterations.

% \begin{equation}
% x_{t+1}\leftarrow \mu - \frac{\sqrt{t}}{\gamma}\frac{1}{t+t_0}\sum_{t=1}^{T}H_i \quad \bar{x}_{t+1} \leftarrow \eta_t x_{t+1}+(1-\eta_t)\bar{x}_{t}
% \label{updatedual}
% \end{equation}

% where the shrinkage of $x_t$ to a freely chosen point $\mu$ is controlled by a free nonnegative parameter $\gamma$, $t_0>0$ is used in order to stabilize the initial iterations and $\bar{x}_1=x_1$. The parameter $\eta_t \equiv t^{-\kappa}$ with $\kappa \in (0.5,1]$ is the step size schedule for which the conditions $\sum_t \eta_t=\infty$ and $\sum_t \eta^2_t < \infty$ (that ensures that $h(\bar{x}_t)$ converges to 0) are met.
%The usual procedure is to tune $x$ during the warmup phase and set it constant for the subsequent iterations.
% The benefits of the choices of the parameters $t_0$ and $\kappa$ are discussed in \citet{hoffman2014nuts}.

% \par The same paper proposes a heuristic for choosing the initial value $\epsilon_1$ so that convergence is reached faster: $\epsilon$ is iteratively multiplied by $2^a$ with $a = \{-1,1\}$ until the acceptance probability of the leapfrog proposal crosses 0.5. Then, simply set $\mu=\log(10\epsilon_1)$ so that the algorithm is more inclined to test on values of $\epsilon>\epsilon_1$.
% \par The tuning of $\epsilon$ for both HMC and NUTS is usually done so that the average Metropolis acceptance rate is equal to a prespecified $\delta \in (0,1)$: setting the statistic $H_t \equiv \delta - \alpha_t$ and the tunable parameter $x\equiv \log{\epsilon}$ in \eqref{updatedual}
% , so that to obtain $h(\epsilon)\equiv \mathbb{E}_t[\alpha_t|\epsilon]=\delta$.
% The only difference concerns the definition of $\alpha_t$, since in the NUTS algorithm there is an accept/reject step at each iteration: in this case, $\alpha_t$ is to be intended as the average probability that HMC would accept  the $(\theta,r)$ state in the last doubling step. In this case, for the NUTS algorithm the user must only provide the target mean acceptance rate $\delta$ and the number of iteration of the tuning phase.

% % below is a code chunk. You don't have to give it a name, but if you do
% % it MUST be unique.
% <<chunkname>>=
%
% f = function(x) x^3 - x - 1
%
% @
% You can do plots and they'll automatically be added to your document.
% <<chunkname2>>=
% plot(f, 1, 2)
% @
%
% \section{A Bit About knitr}
%
% The code chunks you put in don't have to be displayed (and nor does the output),
% if they are displayed they don't have to be evalutated.  To the next chunk I added
% the option \verb|eval=FALSE|
% <<chunk3, eval=FALSE>>=
% rnorm(1e6)
% @
% This code is evaluated, I just choose not to display the output:
% <<chunk4, results='hide'>>=
% 5+5
% @
% And finally you might want your code to be evaluated but not displayed (useful for
% changing options without displaying in your document):
% <<chunk5, echo=FALSE>>=
% options(width=100)
% @
%
% \section{\LaTeX}
%
% \LaTeX itself is complicated if you've never used it before, but I'm sure you'll
% pick it up quickly: there are a lot of guides on the web.  I recommend using the
% \texttt{align} environment (in the \texttt{amsmath} package) for displayed equations:


%\vspace{0.5in}
%You can cite in two ways using the \texttt{natbib} package:
%\citep{articlekey}
%and
%\citet{articlekey}.

% now generate the bibliography from file mybib.bib

\bibliographystyle{plainnat}
\bibliography{mybib}

\end{document}
